[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/hw0/index.html",
    "href": "posts/hw0/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\n\n# In[6]:\n\n\n#penguins.head\n\n\n# In[8]:\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming penguins dataset is already loaded as shown in your output\n# penguins = sns.load_dataset(\"penguins\")\n\n# Construct a pairplot\nsns.pairplot(penguins, hue=\"studyName\", palette=\"Set2\", diag_kind=\"kde\", markers=[\"o\", \"s\", \"D\"])\n\n# Enhance the plot\nplt.suptitle(\"Pairplot of Palmer Penguins Dataset\", size=16)\nplt.subplots_adjust(top=0.9)  # Adjust title position\n\nplt.show()\n\n/Users/owensun/anaconda3/lib/python3.11/site-packages/seaborn/axisgrid.py:118: UserWarning:\n\nThe figure layout has changed to tight"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\nTesttest\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html#introduction",
    "href": "posts/post-with-code/index.html#introduction",
    "title": "Hw0",
    "section": "Introduction",
    "text": "Introduction\nIn this tutorial, we will explore the Palmer Penguins dataset, a well-known dataset in the data science community, often used for data exploration and visualization. We’ll create a pairplot to visualize the relationships between different variables in the dataset."
  },
  {
    "objectID": "posts/post-with-code/index.html#prerequisites",
    "href": "posts/post-with-code/index.html#prerequisites",
    "title": "Hw0",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nPython installed on your machine.\nBasic understanding of Python programming.\nFamiliarity with pandas, seaborn, and matplotlib libraries."
  },
  {
    "objectID": "posts/post-with-code/index.html#step-1-loading-the-dataset",
    "href": "posts/post-with-code/index.html#step-1-loading-the-dataset",
    "title": "Hw0",
    "section": "Step 1: Loading the Dataset",
    "text": "Step 1: Loading the Dataset\nFirst, we need to load the dataset. We will use pandas, a powerful Python library for data manipulation, to load the dataset from a URL.\n\nimport pandas as pd\n\n# URL of the Palmer Penguins dataset\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\n\n# Load the dataset\npenguins = pd.read_csv(url)"
  },
  {
    "objectID": "posts/post-with-code/index.html#step-2-previewing-the-dataset",
    "href": "posts/post-with-code/index.html#step-2-previewing-the-dataset",
    "title": "Hw0",
    "section": "Step 2: Previewing the Dataset",
    "text": "Step 2: Previewing the Dataset\nIt’s always a good practice to preview the data before proceeding with any analysis. This helps to understand the structure of the data.\n\npenguins.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n\n\n\n\n\nThe head() function displays the first five rows of the dataset by default, providing a glimpse into the data we are working with."
  },
  {
    "objectID": "posts/post-with-code/index.html#step-3-importing-visualization-libraries",
    "href": "posts/post-with-code/index.html#step-3-importing-visualization-libraries",
    "title": "Hw0",
    "section": "Step 3: Importing Visualization Libraries",
    "text": "Step 3: Importing Visualization Libraries\nWe will use seaborn and matplotlib for visualization. Seaborn is a Python data visualization library based on matplotlib that provides a high-level interface for drawing attractive and informative statistical graphics.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/post-with-code/index.html#step-4-constructing-a-pairplot",
    "href": "posts/post-with-code/index.html#step-4-constructing-a-pairplot",
    "title": "Hw0",
    "section": "Step 4: Constructing a Pairplot",
    "text": "Step 4: Constructing a Pairplot\nA pairplot allows us to see both distribution of single variables and relationships between two variables. We will create a pairplot using seaborn.\n\n# Construct a pairplot\nsns.pairplot(penguins, hue=\"studyName\", palette=\"Set2\", diag_kind=\"kde\", markers=[\"o\", \"s\", \"D\"])\n\n/Users/owensun/anaconda3/lib/python3.11/site-packages/seaborn/axisgrid.py:118: UserWarning:\n\nThe figure layout has changed to tight\n\n\n\n\n\n\n\n\n\n\nIn this pairplot:\n\nhue=\"studyName\": This parameter will color the points in the plot according to the ‘studyName’ column, allowing us to easily differentiate data points from different studies.\npalette=\"Set2\": This sets the color palette for differentiating the hue levels.\ndiag_kind=\"kde\": This changes the diagonal plots to Kernel Density Estimation plots, which provide a smoother estimate of the distribution of a variable.\nmarkers=[\"o\", \"s\", \"D\"]: Different markers are used for different hue levels, enhancing the visual distinction between them."
  },
  {
    "objectID": "posts/post-with-code/index.html#step-5-enhancing-the-plot",
    "href": "posts/post-with-code/index.html#step-5-enhancing-the-plot",
    "title": "Hw0",
    "section": "Step 5: Enhancing the Plot",
    "text": "Step 5: Enhancing the Plot\nWe will use matplotlib to enhance the plot, such as setting a title and adjusting layout.\n\n# Enhance the plot\nplt.suptitle(\"Pairplot of Palmer Penguins Dataset\", size=16)\nplt.subplots_adjust(top=0.9)  # Adjust title position\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/post-with-code/index.html#step-6-displaying-the-plot",
    "href": "posts/post-with-code/index.html#step-6-displaying-the-plot",
    "title": "Hw0",
    "section": "Step 6: Displaying the Plot",
    "text": "Step 6: Displaying the Plot\nFinally, we display the plot.\n\nplt.show()\n\nConclusion\nCongratulations! You have created a comprehensive pairplot of the Palmer Penguins dataset. This plot provides insights into the relationships between various measurements in the dataset and how they vary across different studies. Visualization is a powerful tool in data analysis, and seaborn along with matplotlib makes it convenient and effective."
  },
  {
    "objectID": "posts/hw3/index.html",
    "href": "posts/hw3/index.html",
    "title": "Flask web Development for messange bank",
    "section": "",
    "text": "url:https://owen020215.github.io/newhw/posts/hw3/\n\nIntroduction\n\nIn this blog, I will be explaining how to build an interesting website that allows us to submit messages and view them.\nMy approach is to build 3 separate pages for the website: the Main page, Submit, and View. The first page is a simple overview page, where users can be redirected to the Submit and View pages.\nHere is my GitHub Repo for the project: https://github.com/owen020215/Flask-Website-main/tree/main\n\n\nMain Page\n\n\n\nMain\n\n\n\nimport scrapy\nfrom scrapy.http import Request\nfrom scrapy.linkextractors import LinkExtractor\nimport random\n\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n    \n    start_urls = ['https://www.themoviedb.org/movie/603-the-matrix']\n\n\ndef parse(self, response):\n        \"\"\"\n        Assume that you start on a movie page, and then navigate to the Cast & Crew page\n        Then calls parse_full_credits(self,response)\n        Does not output anything\n        \"\"\"\n        # concatenate the url by adding the /cast at the end\n        new_urls = response.url + '/cast'\n        yield Request(new_urls, callback=self.parse_full_credits)\n\n\ndef parse_full_credits(self, response):\n        \"\"\"\n        Assume that you start on the Cast & Crew page\n        yield a scrapy.Request for the page of each actor listed on the page\n        Then calls parse_actor_page(self,response) when reaching each actor's page\n        Does not output anything\n        \"\"\"\n        # gets the actors_urls\n        actor_urls = response.css('.pad:nth-child(1) .info a::attr(href)').getall()\n        # concatenate the urls so that they are complete\n        actor_urls = [\"https://www.themoviedb.org\" + url for url in actor_urls]\n        # Yield Request for each page\n        for actor_url in actor_urls:\n            yield Request(actor_url, callback=self.parse_actor_page)\n\n\ndef parse_actor_page(self, response):\n        \"\"\"\n        Assume that you start on the page of an actor\n        yield a dictionary with two key-value pairs in the form \n        {\"actor\" : actor_name, \"movie_or_TV_name\" : movie_or_TV_name}\n        \"\"\"\n        # Get the actor's name from the title\n        actor_name = response.css(\".title a::text\").get()\n        # Get the movies' names from the page\n        movies_and_tv_shows = response.css('.tooltip bdi::text').getall()\n        # Output the dictionary\n        for movie_or_tv_show in movies_and_tv_shows:\n            yield {\"actor\": actor_name, \"movie_or_TV_name\": movie_or_tv_show}"
  },
  {
    "objectID": "posts/hw1/index.html",
    "href": "posts/hw1/index.html",
    "title": "Climate Insights: Exploring Temperature Trends and Patterns (Using SQL and Plotly for More Advanced Data Visualizations)",
    "section": "",
    "text": "url:https://owen020215.github.io/newhw/posts/hw1/\n\n1. Creating a Climate Data Database\nExplanation: Our first step is to construct a database with three critical components: temperatures, stations, and countries. Each table plays a unique role:\n\nTemperatures: Records of temperature readings.\nStations: Geographic and descriptive details of the stations where readings are taken.\nCountries: Information linking stations to their respective countries.\n\nWe use SQL for database management, ensuring efficient data retrieval and organization. This structure allows us to access and analyze climate data effectively.\n\nimport sqlite3\nimport pandas as pd\n# No need to import Plotly Express and sklearn here since they're not used in the provided code snippet.\n\n# Establish a connection to the SQLite database.\nconn = sqlite3.connect(\"weather.db\")\n\n# Function to prepare the DataFrame for further processing or analysis.\ndef prepare_df(df):\n    \"\"\"\n    Prepares the temperature DataFrame by setting a multi-level index, reshaping, \n    and cleaning the data for analysis.\n    \n    Parameters:\n    df (pd.DataFrame): The original DataFrame loaded from a CSV file containing \n                       temperature data with an ID, Year, and monthly temperatures.\n    \n    Returns:\n    pd.DataFrame: A DataFrame with the index reset and columns for ID, Year, Month, \n                  and Temperature, where 'Month' is extracted from the original \n                  column names and 'Temp' is adjusted to represent actual temperatures.\n    \"\"\"\n    # Set a multi-level index using 'ID' and 'Year', then stack the DataFrame to \n    # collapse the month columns into a single column.\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    \n    # Reset the index to turn the indices into columns and rename the resulting columns.\n    df = df.reset_index()\n    df = df.rename(columns={\"level_2\": \"Month\", 0: \"Temp\"})\n    \n    # Convert month column values from string to integer and adjust temperature values.\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"] = df[\"Temp\"] / 100\n    \n    return df\n\n# Load temperature data, prepare it using the defined function, and write to the SQLite database.\ndf = pd.read_csv(\"temps.csv\")\ndf = prepare_df(df)\ndf.to_sql(\"temperatures\", conn, if_exists='replace', index=False)\n\n# Load country codes and station metadata, then write them to the SQLite database.\ndf = pd.read_csv(\"country-codes.csv\")\ndf.to_sql(\"countries\", conn, if_exists='replace', index=False)\n\ndf = pd.read_csv(\"station-metadata.csv\")\ndf.to_sql(\"stations\", conn, if_exists='replace', index=False)\n\n# Close the database connection.\nconn.close()\n\n\nconn = sqlite3.connect('weather.db')\ncursor = conn.cursor()\n\n# Query to list all tables\ncursor.execute(\"PRAGMA table_info('temperatures');\")\ncolumns = cursor.fetchall()\n\n# Print the column names\nprint(\"Column names in 'temperatures' table:\")\nfor col in columns:\n    print(col[1])  # Column name is in the second position\n\nconn.close()\n\nColumn names in 'temperatures' table:\nID\nYear\nMonth\nTemp\n\n\n\n\n2. Writing a Query Function\nExplanation: To extract meaningful information from our database, we’ll write a function query_climate_database() in Python. This function is designed to retrieve temperature readings for a specified country, within a given date range and month. It returns a Pandas dataframe, making data manipulation and analysis in Python straightforward. Here, we focus on clarity and efficiency, using Python’s f-strings for cleaner SQL queries.\n\nfrom climate_database import query_climate_database\nimport inspect\n\n# Use the function\ndf = query_climate_database(db_file='weather.db', country=\"India\", year_begin=1980, year_end=2020, month=1)\nprint(df)\n\n# To print the source code of the function\nprint(inspect.getsource(query_climate_database))\n\n               NAME  LATITUDE  LONGITUDE Country  Year  Month   Temp\n0     PBO_ANANTAPUR    14.583     77.633   India  1980      1  23.48\n1     PBO_ANANTAPUR    14.583     77.633   India  1981      1  24.57\n2     PBO_ANANTAPUR    14.583     77.633   India  1982      1  24.19\n3     PBO_ANANTAPUR    14.583     77.633   India  1983      1  23.51\n4     PBO_ANANTAPUR    14.583     77.633   India  1984      1  24.81\n...             ...       ...        ...     ...   ...    ...    ...\n3147     DARJEELING    27.050     88.270   India  1983      1   5.10\n3148     DARJEELING    27.050     88.270   India  1986      1   6.90\n3149     DARJEELING    27.050     88.270   India  1994      1   8.10\n3150     DARJEELING    27.050     88.270   India  1995      1   5.60\n3151     DARJEELING    27.050     88.270   India  1997      1   5.70\n\n[3152 rows x 7 columns]\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    \n    # Open a new connection to the specified database file\n    conn = sqlite3.connect(db_file)\n    \n\n    cmd = f\"\"\"\n    SELECT \n        S.NAME, \n        S.LATITUDE, \n        S.LONGITUDE, \n        C.NAME as Country, \n        T.Year, \n        T.Month, \n        T.Temp\n    FROM \n        stations S\n    INNER JOIN \n        temperatures T ON T.ID = S.ID\n    INNER JOIN \n        countries C ON S.ID LIKE C.'FIPS 10-4' || '%'\n    WHERE \n        C.NAME = ? AND \n        T.Year BETWEEN ? AND ? AND \n        T.Month = ? AND\n        T.Temp IS NOT NULL\n    \"\"\"\n    \n    # Execute the query and store the results in a pandas DataFrame\n    df = pd.read_sql_query(cmd, conn, params=(country, year_begin, year_end, month))\n    \n    # Close the database connection\n    conn.close()\n    \n    return df\n\n\n\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    \"\"\"\n    Queries the climate database for temperature data for a specific country, within a specified \n    range of years and month, and returns the data as a pandas DataFrame.\n\n    Parameters:\n    - db_file (str): The file path to the SQLite database containing the climate data.\n    - country (str): The name of the country for which to query temperature data.\n    - year_begin (int): The beginning year of the period for the query.\n    - year_end (int): The end year of the period for the query.\n    - month (int): The month for which to query temperature data.\n\n    Returns:\n    pd.DataFrame: A DataFrame containing the station name, latitude, longitude, country name, \n                  year, month, and temperature data for the specified parameters. Each row in the \n                  DataFrame represents a unique record from the database matching the query criteria.\n\n    The query joins three tables: stations, temperatures, and countries, filtering the results \n    by the specified country, year range, and month. It returns only records where the temperature \n    data is not null.\n    \"\"\"\n    # Open a new connection to the specified database file\n    conn = sqlite3.connect(db_file)\n    \n    # SQL command to retrieve the data\n    cmd = f\"\"\"\n    SELECT \n        S.NAME, \n        S.LATITUDE, \n        S.LONGITUDE, \n        C.NAME as Country, \n        T.Year, \n        T.Month, \n        T.Temp\n    FROM \n        stations S\n    INNER JOIN \n        temperatures T ON T.ID = S.ID\n    INNER JOIN \n        countries C ON S.ID LIKE C.'FIPS 10-4' || '%'\n    WHERE \n        C.NAME = ? AND \n        T.Year BETWEEN ? AND ? AND \n        T.Month = ? AND\n        T.Temp IS NOT NULL\n    \"\"\"\n    \n    # Execute the query and store the results in a pandas DataFrame\n    df = pd.read_sql_query(cmd, conn, params=(country, year_begin, year_end, month))\n    \n    # Close the database connection\n    conn.close()\n    \n    return df\n\n\n\nquery_climate_database(db_file='weather.db',country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020,\n                       month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n23.48\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n24.57\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n24.19\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n23.51\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n24.81\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n5.10\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n6.90\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n8.10\n\n\n3150\nDARJEELING\n27.050\n88.270\nIndia\n1995\n1\n5.60\n\n\n3151\nDARJEELING\n27.050\n88.270\nIndia\n1997\n1\n5.70\n\n\n\n\n3152 rows × 7 columns\n\n\n\n\n\nExample and Explanation of query_climate_database():\nCode Explanation: Let’s consider an example where we query temperature data for India from 1980 to 2020 for the month of January. The output will be a neatly organized dataframe showing station names, coordinates, country, year, month, and average temperature.\n\n\n3. Geographic Scatter Function for Yearly Temperature Increases\nExplanation: Our next goal is to visualize how average yearly temperatures change within a country. For this, we create the temperature_coefficient_plot() function. This function generates an interactive scatterplot showing temperature changes at different stations. We’ll use Plotly Express for visualization, enabling us to create dynamic, informative maps. The color intensity of each point on the map indicates the degree of temperature change, providing an immediate visual understanding of climate trends.\n\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nimport plotly.express as px\n\ndef temperature_coefficient(db_file, country, year_begin, year_end, month, min_obs):\n    \"\"\"\n    Calculates the temperature change coefficient for each station in a specified country, \n    within a given time period and month, filtering out stations with observations below a minimum threshold.\n\n    Parameters:\n    - db_file (str): Path to the SQLite database file containing climate data.\n    - country (str): Name of the country for which the temperature coefficient is to be calculated.\n    - year_begin (int): Starting year for the period of interest.\n    - year_end (int): Ending year for the period of interest.\n    - month (int): The month for which the data is to be analyzed.\n    - min_obs (int): Minimum number of observations required for a station to be included in the analysis.\n\n    Returns:\n    pd.DataFrame: A DataFrame with the original data plus a 'change' column representing the temperature change coefficient\n                  for each station that meets the observation threshold. The coefficient reflects the estimated yearly \n                  temperature change based on a linear regression model.\n    \"\"\"\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    value_counts = (df[\"NAME\"].value_counts() &gt;= min_obs) \n    new_value_counts = value_counts[value_counts==True]\n    new_df = df[df['NAME'].isin(new_value_counts.index)].copy()\n    new_df[\"change\"] = new_df[\"NAME\"]\n    \n    for i in new_df['NAME'].unique():\n        df2 = new_df[new_df[\"NAME\"]==i].copy()\n        X = df2[[\"Year\"]].copy()\n        y = df2['Temp'].copy()\n        model = LinearRegression()\n        model.fit(X, y)\n        first_coefficient = model.coef_[0]\n        new_df.loc[new_df[\"NAME\"]==i, \"change\"] = first_coefficient\n        \n    return new_df\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    \"\"\"\n    Generates a scatter map plot showing the estimated yearly increase in temperature for each station in a specified country,\n    within a given time period and month. Stations with observations below a specified minimum are excluded.\n\n    Parameters:\n    - db_file (str): Path to the SQLite database file containing climate data.\n    - country (str): Name of the country for which the temperature change plot is to be generated.\n    - year_begin (int): Starting year for the period of interest.\n    - year_end (int): Ending year for the period of interest.\n    - month (int): The month for which the data is to be visualized.\n    - min_obs (int): Minimum number of observations required for a station to be included in the analysis.\n    - **kwargs: Additional keyword arguments passed to `px.scatter_mapbox`.\n\n    Returns:\n    plotly.graph_objs._figure.Figure: A Plotly Figure object representing the scatter map plot of the estimated yearly temperature \n                                      increase for each qualifying station. The color scale indicates the magnitude of the \n                                      temperature change.\n    \"\"\"\n    df = temperature_coefficient(db_file, country, year_begin, year_end, month, min_obs)\n    df[\"Estimated Yearly Increase\"] = pd.to_numeric(df[\"change\"]).round(4)\n    fig = px.scatter_mapbox(df, \n                            lat=\"LATITUDE\",\n                            lon=\"LONGITUDE\", \n                            hover_name=\"NAME\", \n                            color=\"Estimated Yearly Increase\",\n                            color_continuous_midpoint=0,\n                            title=f\"Estimate of Yearly Change in Temperature of Stations in {country} in month {month} from {year_begin} to {year_end}\",\n                            **kwargs)\n    return fig\n\n\nimport plotly.express as px\ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = temperature_coefficient_plot('weather.db', \"India\", 1980, 2020, 1, \n                                   min_obs=10,\n                                   zoom=2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\n\nfig.show()\n\n                                                \n\n\n\n\nExample of Using temperature_coefficient_plot():\nCode Explanation: Imagine creating a plot for India, showing temperature changes in January from 1980 to 2020. The plot not only reveals geographical patterns in temperature changes but also provides detailed information on hover, like station names and precise temperature change values\n\nimport plotly.express as px\ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = temperature_coefficient_plot('weather.db', \"United States\", 1970, 1990, 2, \n                                   min_obs = 10,\n                                   zoom = 2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n                                                \n\n\nImagine creating a plot for India, showing temperature changes in January from 1980 to 2020.\n\n\n4. Additional Interesting Figures\nExplanation: To further explore our climate data, we’ll create two additional types of interactive visualizations. Each will address a unique question and provide different insights into the dataset.\nWe want to first answer the question: Which station in which year and month had the lowest average temperature?\n\nimport sqlite3\nimport pandas as pd\n\ndatabase_path = 'weather.db'\nconn = sqlite3.connect(database_path)\n\ndef query_climate_database2(limit=10):\n    \"\"\"\n    Queries the climate database to retrieve a specified number of records with the lowest temperatures,\n    along with the corresponding country code, year, and month.\n\n    The function executes a SQL query to select the top records with the lowest temperatures from\n    the 'temperatures' table, ordering the results in ascending order by temperature. It returns a subset\n    of information including the country code derived from the first two characters of the station ID,\n    the temperature, year, and month.\n\n    Parameters:\n    - limit (int): The number of records to retrieve, defaulting to 10. Specifies the limit for the query\n                   to restrict the number of rows returned, focusing on the lowest temperatures.\n\n    Returns:\n    pd.DataFrame: A DataFrame containing the query results with columns for the country code, temperature,\n                  year, and month. This DataFrame is sorted by temperature in ascending order, showcasing\n                  the records with the lowest temperatures up to the specified limit.\n\n    Note: This function assumes an active database connection 'conn' is available and correctly configured\n          to query from the 'temperatures' table.\n    \"\"\"\n    \n    cmd = f\"\"\"\n    SELECT SUBSTR(id, 1, 2) AS country, temp, year, month\n    FROM temperatures\n    ORDER BY temp ASC LIMIT {limit}\n    \"\"\"\n\n    df = pd.read_sql_query(cmd, conn)\n    return df\n\n# Example call to the function\nquery_climate_database2(10)\n\n\n\n\n\n\n\n\ncountry\nTemp\nYear\nMonth\n\n\n\n\n0\nAY\n-75.00\n1987\n8\n\n\n1\nAY\n-73.80\n1983\n7\n\n\n2\nAY\n-73.55\n1978\n8\n\n\n3\nAY\n-72.89\n1967\n8\n\n\n4\nAY\n-72.83\n2019\n6\n\n\n5\nAY\n-72.80\n1975\n8\n\n\n6\nAY\n-72.80\n1997\n7\n\n\n7\nAY\n-72.35\n1982\n8\n\n\n8\nAY\n-72.19\n1979\n7\n\n\n9\nAY\n-71.87\n1998\n9\n\n\n\n\n\n\n\nThen, we want to visualize our response to the question: Which station in which year and month had the lowest average temperature?\n\nimport plotly.express as px\n\ndef temperature_coefficient_plot(n=100, **kwargs):\n    \"\"\"\n    Generates a 3D scatter plot visualizing the n lowest temperatures recorded, showing their distribution across different years and months, and color-coded by country. This function queries the climate database for the n lowest temperatures and their corresponding year and month of occurrence, along with the country codes. It then uses Plotly Express to create a 3D scatter plot of these data points, with temperature on the x-axis, year on the y-axis, and month on the z-axis. Points are color-coded by country to provide visual differentiation between different countries' data. Parameters: - n (int): The number of records to retrieve and visualize, focusing on the lowest temperatures. Defaults to 100 if not specified. - **kwargs: Additional keyword arguments to pass to the Plotly Express scatter_3d function for customizing the plot. This can include arguments such as marker size, labels, and color scale options. Returns: plotly.graph_objs._figure.Figure: A Plotly Figure object representing the 3D scatter plot. The figure can be displayed in Jupyter notebooks or saved to an HTML file using Plotly's built-in functions. Note: This function assumes that a function `query_climate_database2` is defined and accessible, which is responsible for querying the database to retrieve the specified number of records with the lowest temperatures, along with their year, month, and country code.\n    \"\"\"\n    df = query_climate_database2(n)\n\n    fig = px.scatter_3d(df,\n                        x=\"Temp\",\n                        y=\"Year\",\n                        z=\"Month\",\n                        color=\"country\",\n                        opacity=0.5,\n                        title=f\"Year and Month of the {n} Lowest Temperature\",\n                        **kwargs)\n    \n    return fig\n\n# Example call to the function\n# Note: Ensure that query_climate_database2 function is defined and accessible in your script.\ntemperature_coefficient_plot(150)\n\n                                                \n\n\nThe function is designed to visualize temperature data, showing the relationship between the year, temperature, and potentially other variables.\n\nimport plotly.express as px\n\"\"\"\n    Generates a 2D scatter plot faceted by a specified variable.\n\n    This function queries the climate database to retrieve the necessary data and creates a 2D scatter plot\n    with year on the x-axis, temperature on the y-axis, and color-coded by country. The plot is faceted by\n    the specified variable (e.g., 'Month' or another categorical variable) to visualize the data across different\n    categories.\n\n    Parameters:\n    - n (int, optional): The number of records to retrieve for plotting. Defaults to 100.\n    - facet_by (str, optional): The variable to facet the plot by. Defaults to 'Month'.\n    - **kwargs: Additional keyword arguments for customizing the Plotly scatter plot.\n\n    Returns:\n    plotly.graph_objs._figure.Figure: A Plotly Figure object representing the 2D scatter plot.\n\n    Note: Assumes the existence of a function 'query_climate_database2(n)' that returns a DataFrame\n          with the necessary data, including columns for year, temperature, and country.\n  \"\"\"\ndef temperature_coefficient_plot_2d(n=100, facet_by='Month', **kwargs):\n  \n    # Assuming query_climate_database2(n) returns a DataFrame with the necessary data\n    \n    df = query_climate_database2(n)\n\n    # Create a 2D scatter plot faceted by the specified variable (e.g., 'Month')\n    fig = px.scatter(df,\n                     x=\"Year\",\n                     y=\"Temp\",\n                     color=\"country\",\n                     facet_col=facet_by,  # Faceting by 'Month' or another variable\n                     opacity=0.5,\n                     title=f\"Year and Month of the {n} Lowest Temperatures\",\n                     **kwargs)\n    \n    # Adjust layout for readability\n    fig.update_layout(autosize=True)\n    fig.update_traces(marker=dict(size=5))\n                            \n    return fig\n\n# Example call to the modified function\nfig = temperature_coefficient_plot_2d(150, facet_by='Month')\nfig.show()\n\n                                                \n\n\nWhen compare the highest temperatures between 2 countries, which country has the higher temperature?\n\ndatabase_path = 'weather.db'\nconn = sqlite3.connect(database_path)\nimport plotly.express as px\n\"\"\"\n    Generates a box plot comparing the highest temperatures of two countries.\n\n    This function queries the climate database for the n highest temperatures for each specified country\n    and visualizes the results in a comparative box plot. The plot showcases the distribution of the top\n    temperatures, allowing for easy comparison between the two countries.\n\n    Parameters:\n    - country1 (str): The country code for the first country.\n    - country2 (str): The country code for the second country.\n    - n (int, optional): The number of top temperatures to retrieve for each country. Defaults to 100.\n    - **kwargs: Additional keyword arguments for customizing the plotly box plot.\n\n    Returns:\n    plotly.graph_objs._figure.Figure: A Plotly Figure object representing the box plot.\n\n    Note: Requires an active database connection 'conn' and assumes the existence of a 'temperatures'\n    table with appropriate schema. The function concatenates data from both countries for comparison.\n\"\"\"\ndef temperature_coefficient_plot(country1, country2, n = 100, **kwargs):\n    cmd = \\\n    f\"\"\"\n    SELECT SUBSTRING(id,1,2) AS country, temp\n    FROM temperatures\n    WHERE country = \"{country1}\"\n    ORDER BY temp DESC LIMIT {n}\n    \"\"\"\n\n    df = pd.read_sql_query(cmd, conn)\n    cmd = \\\n    f\"\"\"\n    SELECT SUBSTRING(id,1,2) AS country, temp\n    FROM temperatures\n    WHERE country = \"{country2}\"\n    ORDER BY temp DESC LIMIT {n}\n    \"\"\"\n\n    df1 = pd.read_sql_query(cmd, conn)\n    df = pd.concat([df,df1])\n    fig = px.box(df, \n             \"Temp\",\n             color = \"country\",\n             width = 600,\n             height = 300,\n             title = f\"Comparing highest {n} temperatures of {country1} versus {country2}\")\n    \n                            \n    return fig\n\ntemperature_coefficient_plot(\"US\",\"CA\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "newhw0",
    "section": "",
    "text": "Flask web Development for messange bank\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nOwen Sun\n\n\n\n\n\n\n\n\n\n\n\n\nClimate Insights: Exploring Temperature Trends and Patterns (Using SQL and Plotly for More Advanced Data Visualizations)\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 27, 2024\n\n\nOwen Sun\n\n\n\n\n\n\n\n\n\n\n\n\nHw0\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nOwen Sun\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]